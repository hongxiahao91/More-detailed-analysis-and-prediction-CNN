{
  "cells": [
    {
      "metadata": {
        "_cell_guid": "19ff9d0b-d32d-4325-a19f-2ccbfa7d2dff",
        "_uuid": "9206c5863724e1af01281071e0f0ee5109ef431b"
      },
      "cell_type": "markdown",
      "source": "# Goal\nThe goal is to use a simple model to classify x-ray images in Keras, the notebook how to use the ```flow_from_dataframe``` to deal with messier datasets"
    },
    {
      "metadata": {
        "_cell_guid": "f42f6560-edf0-4efb-85a6-6e945e50895b",
        "_uuid": "3300a1edbf2e8122d88093998eb503a6fab8a719",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom skimage.io import imread\nimport cv2\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nfrom glob import glob\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "91515e0332ae8329d3aa728ee2fe5eeba329b3db"
      },
      "cell_type": "code",
      "source": "!ls ../input/sample/sample",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "cf249b3e8fac1f85d3b9757102b8eb8ce5d73b52"
      },
      "cell_type": "code",
      "source": "!mkdir ~/.keras\n!mkdir ~/.keras/models\n!cp ../input/keraspretrainedmodels/keras-pretrained-models/*notop* ~/.keras/models/\n!cp ../input/keraspretrainedmodels/keras-pretrained-models/imagenet_class_index.json ~/.keras/models/\n#!cp ../input/keraspretrainedmodels/keras-pretrained-models/resnet50* ~/.keras/models/",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f91d2545ff5ccbd5633db0983ed0622b9ceb5e2e"
      },
      "cell_type": "markdown",
      "source": "import os\n\ncache_dir = os.path.expanduser(os.path.join('~', '.keras'))\nif not os.path.exists(cache_dir):\n    os.makedirs(cache_dir)\n\n# Create symbolic links for trained models.\n# Thanks to Lem Lordje Ko for the idea\n# https://www.kaggle.com/lemonkoala/pretrained-keras-models-symlinked-not-copied\nmodels_symlink = os.path.join(cache_dir, 'models')\nif not os.path.exists(models_symlink):\n    os.symlink('/kaggle/input/keras-pretrained-models/', models_symlink)"
    },
    {
      "metadata": {
        "_cell_guid": "9a342cdc-0823-490d-9a3a-a53fb7c33727",
        "_uuid": "fe804e7c294e2d290e27b037bf1ba56177abab70",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# ../input/\nPATH = os.path.abspath(os.path.join('..', 'input'))\n\n# ../input/sample/images/\nSOURCE_IMAGES = os.path.join(PATH, \"sample\", \"sample\",\"images\")\n\n# ../input/sample/images/*.png\nimages = glob(os.path.join(SOURCE_IMAGES, \"*.png\"))\n\n# Load labels\nall_xray_df = pd.read_csv('../input/sample/sample_labels.csv')\nall_image_paths = {os.path.basename(x): x for x in images}\nprint('Scans found:', len(all_image_paths), ', Total Headers', all_xray_df.shape[0])\nall_xray_df['path'] = all_xray_df['Image Index'].map(all_image_paths.get)\nall_xray_df['Patient Age'] = all_xray_df['Patient Age'].map(lambda x: int(x[:-1]))\nall_xray_df['Patient Age'] = np.clip(all_xray_df['Patient Age'], 5, 100)\nall_xray_df.sample(3)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "0d674a43-170f-4ca6-a9b4-edc64ab89c35",
        "_uuid": "9a1669750b7cffcae1b7a2eb4307b85472dff192"
      },
      "cell_type": "markdown",
      "source": "# Preprocessing Labels\nHere we take the labels and make them into a more clear format. The primary step is to see the distribution of findings and then to convert them to simple binary labels"
    },
    {
      "metadata": {
        "_cell_guid": "d75ed03e-986d-4f3f-81af-c910d194f390",
        "_uuid": "0c5123f65edf349f8ad2e5c5f55ac484d974f5c7",
        "trusted": true
      },
      "cell_type": "code",
      "source": "label_counts = all_xray_df['Finding Labels'].value_counts()[:15]\nfig, ax1 = plt.subplots(1,1,figsize = (12, 8))\nax1.bar(np.arange(len(label_counts))+0.5, label_counts)\nax1.set_xticks(np.arange(len(label_counts))+0.5)\n_ = ax1.set_xticklabels(label_counts.index, rotation = 90)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "a9ff3a04-254d-4667-b0a3-869bbd92b08b",
        "_uuid": "78b4425b0a8932bb33864b5a3712611004687a48",
        "trusted": true
      },
      "cell_type": "code",
      "source": "all_xray_df['Finding Labels'] = all_xray_df['Finding Labels'].map(lambda x: x.replace('No Finding', ''))\nfrom itertools import chain\nall_labels = np.unique(list(chain(*all_xray_df['Finding Labels'].map(lambda x: x.split('|')).tolist())))\nall_labels = [x for x in all_labels if len(x)>0]\nprint('All Labels ({}): {}'.format(len(all_labels), all_labels))\nfor c_label in all_labels:\n    if len(c_label)>1: # leave out empty labels\n        all_xray_df[c_label] = all_xray_df['Finding Labels'].map(lambda finding: 1.0 if c_label in finding else 0)\nall_xray_df.head(5)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "bb365472b2950ff1e4ff11add1772ce2fc3ee760"
      },
      "cell_type": "code",
      "source": "all_xray_df[['Patient Age', 'Infiltration']].hist(figsize = (10, 5))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "af3a31c3f07bab6aec6c54aa153d04366604daa9"
      },
      "cell_type": "code",
      "source": "###Balance the whole data by droping the oversampling set\npositive_cases = np.sum(all_xray_df['Infiltration']==1)//2\noversample_factor = 4 # maximum number of cases in negative group so it isn't super rare\nall_xray_df = all_xray_df.groupby(['Patient Gender', 'Infiltration']).apply(lambda x: x.sample(min(oversample_factor*positive_cases, x.shape[0]), replace = False)).reset_index(drop = True)\n\nprint(more_balanced_df['Infiltration'].value_counts())\nall_xray_df[['Patient Age', 'Infiltration']].hist(figsize = (10, 5))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "a1367d63-4c7b-4e47-b19f-9a26d1f89476",
        "_uuid": "6ed6489bbd618fb419ceca2bbd8c300694f1d4ed",
        "scrolled": true
      },
      "cell_type": "markdown",
      "source": "# Prepare Training Data\nHere we split the data into training and validation sets and create a single vector (disease_vec) with the 0/1 outputs for the disease status (what the model will try and predict)"
    },
    {
      "metadata": {
        "_cell_guid": "5feddc96-7958-4d34-81f1-10eba94ab1b6",
        "_uuid": "8c7dc722de08243cc763d23928708f9c040bbdc6",
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.model_selection import train_test_split\ntrain_df, valid_df = train_test_split(all_xray_df, \n                                   test_size = 0.2, \n                                   random_state = 2018,\n                                   stratify = all_xray_df[['Patient Gender','Patient Gender']])\nprint('train', train_df.shape[0], 'validation', valid_df.shape[0])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3c7566fada00443ed06ff36fa0ed5f53a26cd7fa"
      },
      "cell_type": "code",
      "source": "###Balance the data in the training set\nnew_train_df = train_df.groupby(['Infiltration']).apply(lambda x: x.sample(1900, replace = True)).reset_index(drop = True)\nprint('New Data Size:', new_train_df.shape[0], 'Old Size:', train_df.shape[0])\nnew_train_df[['Infiltration', 'Patient Age']].hist(figsize = (10, 5))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "7178cb8d-f220-4422-93ae-2469f0c97493",
        "_uuid": "0115346eb989e7eaeffa3643d05c654ec5ceb7c2"
      },
      "cell_type": "markdown",
      "source": "# Create Data Generators\nHere we make the data generators for loading and randomly transforming images"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a1b5687116c2f9063b1f6af88788b4ac9acf4514"
      },
      "cell_type": "code",
      "source": "#from keras.applications.mobilenet import MobileNet\nfrom keras.applications.resnet50 import ResNet50, preprocess_input\n#from keras.applications.vgg16 import VGG16, preprocess_input\n#from keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\nfrom keras.layers import GlobalAveragePooling2D, Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D, BatchNormalization\nfrom keras.models import Sequential\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.optimizers import Adam, RMSprop",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "30eaf01b-8ec0-4407-9d25-f87ca1f48e8a",
        "_uuid": "b5e42124376584390e925a06c4cee564285e43b3",
        "trusted": true
      },
      "cell_type": "code",
      "source": "\nIMG_SIZE = (484, 484)\ncore_idg = ImageDataGenerator(preprocessing_function=preprocess_input,\n                              samplewise_center=False, \n                              samplewise_std_normalization=False, \n                              horizontal_flip= False,  \n                              vertical_flip = False, \n                              height_shift_range= 0.1, \n                              width_shift_range=0.1, \n                              rotation_range=10, \n                              shear_range = 0.01,\n                              fill_mode = 'nearest',\n                              zoom_range=0.15)\nval_idg = ImageDataGenerator(preprocessing_function=preprocess_input)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "b67dc5fa-d91b-420a-aaa7-b3991313127a",
        "_uuid": "dbb93f7f8248031563ec7042d978650c0c957c1f",
        "trusted": true
      },
      "cell_type": "code",
      "source": "def flow_from_dataframe(img_data_gen, in_df, path_col, y_col, **dflow_args):\n    base_dir = os.path.dirname(in_df[path_col].values[0])\n    print('## Ignore next message from keras, values are replaced anyways')\n    df_gen = img_data_gen.flow_from_directory(base_dir, \n                                     class_mode = 'sparse',\n                                    **dflow_args)\n    df_gen.filenames = in_df[path_col].values\n    df_gen.classes = np.stack(in_df[y_col].values)\n    df_gen.samples = in_df.shape[0]\n    df_gen.n = in_df.shape[0]\n    df_gen._set_index_array()\n    df_gen.directory = '' # since we have the full path\n    print('Reinserting dataframe: {} images'.format(in_df.shape[0]))\n    return df_gen",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "dc4d027c-f5c4-48b8-8ab6-b41971ad514f",
        "_uuid": "cc92b74f28987fee4971e60a71f74660693f4278",
        "trusted": true
      },
      "cell_type": "code",
      "source": "train_gen = flow_from_dataframe(core_idg, new_train_df, \n                             path_col = 'path',\n                            y_col = 'Infiltration', \n                            target_size = IMG_SIZE,\n                             color_mode = 'rgb',\n                            batch_size = 256)\n\nvalid_gen = flow_from_dataframe(core_idg, valid_df, \n                             path_col = 'path',\n                            y_col = 'Infiltration', \n                            target_size = IMG_SIZE,\n                             color_mode = 'rgb',\n                            batch_size = 384) # we can use much larger batches for evaluation\n# used a fixed dataset for evaluating the algorithm\ntest_X, test_Y = next(flow_from_dataframe(core_idg, valid_df, \n                             path_col = 'path',\n                            y_col = 'Infiltration', \n                            target_size = IMG_SIZE,\n                             color_mode = 'rgb',\n                            batch_size = 384)) # one big batch",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "0621048f-3d4c-4eb7-aaee-0c53f7cbf26a",
        "_uuid": "2852ef2fe07eb6d8e2caf056d1428d153afad65f",
        "trusted": true
      },
      "cell_type": "code",
      "source": "t_x, t_y = next(train_gen)\nfig, m_axs = plt.subplots(2, 4, figsize = (16, 8))\nfor (c_x, c_y, c_ax) in zip(t_x, t_y, m_axs.flatten()):\n    c_ax.imshow(c_x[:,:,0], cmap = 'bone')\n    c_ax.set_title('%s' % ('Infiltration' if c_y>0.5 else 'Else'))\n    c_ax.axis('off')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "cce3c89c-4292-4092-9317-ca066d72e354",
        "_uuid": "5b0ec78f2ffa8137dce37744f38a40782aafb54d"
      },
      "cell_type": "markdown",
      "source": "# Create a simple model\nHere we make a simple model to train using MobileNet as a base and then adding a GAP layer (Flatten could also be added), dropout, and a fully-connected layer to calculate specific features"
    },
    {
      "metadata": {
        "_cell_guid": "235846d4-3ef1-4888-a276-6134ad572415",
        "_uuid": "a447f8cc7274c06555849a40881fb903aca7001a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "\nfrom keras import regularizers\nbase_model = ResNet50(input_shape =  (IMG_SIZE[0],IMG_SIZE[1],3), include_top = False, weights = 'imagenet')\n#base_model.trainable = False\nfor layer in base_model.layers[:-4]:\n    layer.trainable= False\nfor layer in base_model.layers:\n    if 'bn' in layer.name:\n        layer.trainable = False\n    print(layer,layer.trainable)\nprint (len(base_model.layers))\nmodel = Sequential()\nmodel.add(base_model)\nmodel.add(GlobalAveragePooling2D())\nmodel.add(Dropout(0.5))\nmodel.add(Dense(512, activation = 'relu',kernel_regularizer=regularizers.l2(0.0001)))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1, activation = 'sigmoid'))\nmodel.compile(optimizer = \"adam\", loss = 'binary_crossentropy',metrics = ['binary_accuracy', 'mae'])\nmodel.summary()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "5bc8e0b274e93e5949481858fe1a1fa62b884c51"
      },
      "cell_type": "markdown",
      "source": "from keras.layers import GlobalAveragePooling2D, Dense, Dropout, Flatten, Input, Conv2D, multiply, LocallyConnected2D, Lambda, AvgPool2D\nfrom keras.models import Model\nfrom keras.layers import BatchNormalization\n\nbase_model = ResNet50(input_shape =  (IMG_SIZE[0],IMG_SIZE[1],3), \n                                 include_top = False, weights = 'imagenet')\n#base_model.trainable = False\nfor layer in base_model.layers[:-4]:\n    layer.trainable= False\nfor layer in base_model.layers:\n    if 'bn' in layer.name:\n        layer.trainable = False\n    print(layer,layer.trainable)\n\npt_features = Input(base_model.get_output_shape_at(0)[1:], name = 'feature_input')\npt_depth = base_model.get_output_shape_at(0)[-1]\n#print(base_model.get_output_shape_at(0)[-1])\nbn_features = BatchNormalization()(pt_features)\n\n# here we do an attention mechanism to turn pixels in the GAP on an off\nattn_layer = Conv2D(128, kernel_size = (1,1), padding = 'same', activation = 'elu')(bn_features)\nattn_layer = Conv2D(32, kernel_size = (1,1), padding = 'same', activation = 'elu')(attn_layer)\nattn_layer = Conv2D(16, kernel_size = (1,1), padding = 'same', activation = 'elu')(attn_layer)\nattn_layer = AvgPool2D((2,2), strides = (1,1), padding = 'same')(attn_layer) # smooth results\nattn_layer = Conv2D(1, \n                    kernel_size = (1,1), \n                    padding = 'valid', \n                    activation = 'sigmoid')(attn_layer)\n# fan it out to all of the channels\nup_c2_w = np.ones((1, 1, 1, pt_depth))\nup_c2 = Conv2D(pt_depth, kernel_size = (1,1), padding = 'same', \n               activation = 'linear', use_bias = False, weights = [up_c2_w])\nup_c2.trainable = False\nattn_layer = up_c2(attn_layer)\n\nmask_features = multiply([attn_layer, bn_features])\ngap_features = GlobalAveragePooling2D()(mask_features)\ngap_mask = GlobalAveragePooling2D()(attn_layer)\n# to account for missing values from the attention model\ngap = Lambda(lambda x: x[0]/x[1], name = 'RescaleGAP')([gap_features, gap_mask])\ngap_dr = Dropout(0.5)(gap)\ndr_steps = Dropout(0.5)(Dense(128, activation = 'elu')(gap_dr))\nout_layer = Dense(1, activation = 'sigmoid')(dr_steps)\n\nattn_model = Model(inputs = [pt_features], outputs = [out_layer], name = 'attention_model')\n\nattn_model.compile(optimizer = 'adam', loss = 'binary_crossentropy',\n                           metrics = ['binary_accuracy'])\n\nattn_model.summary()    "
    },
    {
      "metadata": {
        "_uuid": "bf5ea2f3e660b488bbfb443cfbb02e312f57020b"
      },
      "cell_type": "markdown",
      "source": "from keras.models import Sequential\nfrom keras.optimizers import Adam\nmodel = Sequential(name = 'combined_model')\n#base_model.trainable = False\nmodel.add(base_model)\nmodel.add(attn_model)\nmodel.compile(optimizer = Adam(lr = 1e-3), loss = 'binary_crossentropy',\n                           metrics = ['binary_accuracy'])\nmodel.summary()"
    },
    {
      "metadata": {
        "_cell_guid": "1acd1753-dae2-440d-a9d5-f3bbebfe446f",
        "_uuid": "90a131f99bea8b77fba54024e261a97e24dfc6c1",
        "trusted": true
      },
      "cell_type": "code",
      "source": "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\nweight_path=\"{}_weights.best.hdf5\".format('xray_class')\n\ncheckpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1, \n                             save_best_only=True, mode='min', save_weights_only = True)\n\nearly = EarlyStopping(monitor=\"val_loss\", \n                      mode=\"min\", \n                      patience=5)\ncallbacks_list = [checkpoint, early]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "e5ad629e-15a3-4c96-ac74-db8077b101fe",
        "_uuid": "eba5247e4a767def4b4ead6e2f02f3c334edbbf0"
      },
      "cell_type": "markdown",
      "source": "# First Round\nHere we do a first round of training to get a few initial low hanging fruit results"
    },
    {
      "metadata": {
        "_cell_guid": "c269083c-7617-4c16-8f96-353c1f3d8eef",
        "_uuid": "cbdfcf827510dfb3bdba6ab08ff60e21838d6987",
        "trusted": true
      },
      "cell_type": "code",
      "source": "train_gen.batch_size = 24\nvalid_gen.batch_size = 32\nmodel.fit_generator(train_gen, \n                    steps_per_epoch=train_gen.samples//train_gen.batch_size,\n                    validation_data = valid_gen,\n                    validation_steps = valid_gen.samples//valid_gen.batch_size,\n                    epochs = 1, \n                    callbacks = callbacks_list,\n                    workers = 3)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "6c2fe734-8f87-4537-81e0-d0ce68bc2545",
        "_uuid": "8a03574bc1f2b3441538c2408fc158324d6d23df",
        "collapsed": true
      },
      "cell_type": "markdown",
      "source": "# Continued Training\nNow we do a much longer training process to see how the results improve"
    },
    {
      "metadata": {
        "_cell_guid": "80b6ede7-052b-4fa2-ab97-bed0199db681",
        "_uuid": "0b35cd7ef77680d2aa180812622d89388b8fff63",
        "trusted": true
      },
      "cell_type": "code",
      "source": "history = model.fit_generator(train_gen, \n                              steps_per_epoch = train_gen.samples//train_gen.batch_size,\n                              validation_data =  valid_gen, \n                              validation_steps = valid_gen.samples//valid_gen.batch_size,\n                              epochs = 15, \n                              callbacks = callbacks_list)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "74c46b271dfbe553973d56749abdae0b6484a2fb"
      },
      "cell_type": "code",
      "source": "import matplotlib.pyplot as plt\n\nplt.plot(history.history['binary_accuracy'])\nplt.plot(history.history['val_binary_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\n#plt.ylim(0.8,0.96)\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\nfig.savefig('model_accuracy.png', dpi=300)\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\nfig.savefig('model_loss.png', dpi=300)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "9447be5c648631b08da06acba1c89583466dc166",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# load the best weights\nmodel.load_weights(weight_path)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "97dd6d26-8d12-4aa5-8544-6bde2f8200a6",
        "_uuid": "2f358c745432e497adfac31c6d97abc8b61bd0eb",
        "trusted": true
      },
      "cell_type": "code",
      "source": "pred_Y = model.predict(test_X, batch_size = 32, verbose = True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "31990e46-1437-4945-aaa5-b31b377d6538",
        "_uuid": "a5dd26025391067cd0220b7502b193e5e095edbd",
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.metrics import roc_curve, roc_auc_score\nfpr, tpr, _ = roc_curve(test_Y, pred_Y)\nfig, ax1 = plt.subplots(1,1, figsize = (5, 5), dpi = 250)\nax1.plot(fpr, tpr, 'b.-', label = 'RestNet-Model (AUC:%2.2f)' % roc_auc_score(test_Y, pred_Y))\nax1.plot(fpr, fpr, 'k-', label = 'Random Guessing')\nax1.legend(loc = 4)\nax1.set_xlabel('False Positive Rate')\nax1.set_ylabel('True Positive Rate');\nfig.savefig('roc.pdf')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "166f69a186717b9f3b2733a87bc26d5bee3ffd45"
      },
      "cell_type": "code",
      "source": "from sklearn.metrics import classification_report, confusion_matrix\nplt.matshow(confusion_matrix(test_Y, pred_Y>0.5))\nprint(classification_report(test_Y, pred_Y>0.5, target_names = ['Else', 'Infiltration']))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "48aff5bd-c927-44ae-abd3-1de884969d3b",
        "_uuid": "817ed988ed86bc7941065eeac676d1b50cef5d0b",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "68354276-ebbb-46ca-acd6-9e8cd1354bba",
        "_uuid": "6c186e1070db679fb62a4a08e4f42a7ece925aff",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}