{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom skimage.io import imread\nimport cv2\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nfrom glob import glob\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8ff102935951085875879d0781c0798de15d2c55"
      },
      "cell_type": "code",
      "source": "!mkdir ~/.keras\n!mkdir ~/.keras/models\n!cp ../input/keraspretrainedmodels/keras-pretrained-models/*notop* ~/.keras/models/\n!cp ../input/keraspretrainedmodels/keras-pretrained-models/imagenet_class_index.json ~/.keras/models/\n#!cp ../input/keraspretrainedmodels/keras-pretrained-models/resnet50* ~/.keras/models/",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# ../input/\nPATH = os.path.abspath(os.path.join('..', 'input'))\n\n# ../input/sample/images/\nSOURCE_IMAGES = os.path.join(PATH, \"sample\", \"sample\",\"images\")\n\n# ../input/sample/images/*.png\nimages = glob(os.path.join(SOURCE_IMAGES, \"*.png\"))\n\n# Load labels\nlabels = pd.read_csv('../input/sample/sample_labels.csv')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "29cf9a24bd98803288b040332377e7725a0cbb17"
      },
      "cell_type": "code",
      "source": "# load in all of the images\nlabels['path'] = labels['Image Index'].apply(lambda x: os.path.join(SOURCE_IMAGES,x))\n#labels['image'] = labels['path'].map(imread)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0992e46654fee2e18d7688a092e97471e1d104aa"
      },
      "cell_type": "code",
      "source": "# see the image size distribution\n#labels['image'].map(lambda x: x.shape).value_counts()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d12025a59a96afdb184d0d5a2d436424f6d04690"
      },
      "cell_type": "code",
      "source": "labels['NumLabel']=labels['Finding Labels'].apply(lambda x: 0 if 'No Finding' in x else 1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "96de15012de333f7f682be6ce22c2942ff34ae63"
      },
      "cell_type": "code",
      "source": "labels.groupby('NumLabel').count()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "91b50c5c5ea2b9a176a17650e0bf5e035d84bb22"
      },
      "cell_type": "code",
      "source": "labels.head(5)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5ff614b88d34d1f00a112bd4c5c43a6242121ec2"
      },
      "cell_type": "markdown",
      "source": "labels['NumLabel']=labels['Finding Labels'].apply(lambda x: 'No Finding' if 'No Finding' in x else 'Found!')"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "bc42737a94b4316c23406be58a66f9973a103536"
      },
      "cell_type": "markdown",
      "source": "from itertools import chain\nall_labels = np.unique(list(chain(labels['NumLabel'])))\nall_labels = [x for x in all_labels if len(x)>0]\nprint('All Labels ({}): {}'.format(len(all_labels), all_labels))\nfor c_label in all_labels:\n    if len(c_label)>1: # leave out empty labels\n        labels[c_label] = labels['NumLabel'].map(lambda finding: 1.0 if c_label in finding else 0)\nlabels.sample(13)"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f16b675d02718841a58e64fa408b63787e456756"
      },
      "cell_type": "markdown",
      "source": "# keep at least 1000 cases\nMIN_CASES = 500\nall_labels = [c_label for c_label in all_labels if labels[c_label].sum()>MIN_CASES]\nprint('Clean Labels ({})'.format(len(all_labels)), \n      [(c_label,int(labels[c_label].sum())) for c_label in all_labels])"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "bb90cf3081808ed329d0e27a95ef2ea85975bdd3"
      },
      "cell_type": "markdown",
      "source": "labels['disease_vec'] = labels.apply(lambda x: [x[all_labels].values], 1).map(lambda x: x[0])"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "86ec839d84a0011d5e8f5e920d9f5a7e27e53632"
      },
      "cell_type": "markdown",
      "source": "labels.head(13)"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9f616edd9d9bc22429191732528942f51372d442"
      },
      "cell_type": "code",
      "source": "from sklearn.model_selection import train_test_split \ntrain_df, test_df = train_test_split(labels, \n                                   test_size = 0.2, \n                                   random_state = 2018,\n                                   stratify = labels[['NumLabel', 'Patient Gender']])\nprint('train', train_df.shape[0], 'validation', test_df.shape[0])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ac3ecee366df5216a0aaf7054b9b96e663579d42"
      },
      "cell_type": "code",
      "source": "#from keras.applications.xception import Xception, preprocess_input\n#from keras.applications.resnet50 import ResNet50, preprocess_input\nfrom keras.applications.vgg16 import VGG16, preprocess_input\n#from keras.applications.inception_v3 import InceptionV3, preprocess_input\n#from keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\nfrom keras.layers import GlobalAveragePooling2D, Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D, BatchNormalization\nfrom keras.models import Sequential\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.optimizers import Adam, RMSprop\nfrom keras import regularizers",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "94a58d023bdc412608d51800e06df1447bb56694"
      },
      "cell_type": "code",
      "source": "IMG_SIZE = (128, 128)\ncore_idg = ImageDataGenerator(preprocessing_function=preprocess_input,\n                              samplewise_center=True, \n                              samplewise_std_normalization=True, \n                              horizontal_flip = True, \n                              vertical_flip = False, \n                              rescale = 1.0/255,\n                              height_shift_range= 0.15, \n                              width_shift_range=0.15, \n                              rotation_range=40, \n                              shear_range = 0.15,\n                              fill_mode = 'nearest',\n                              zoom_range=0.15)\nval_idg = ImageDataGenerator(preprocessing_function=preprocess_input,\n                            rescale = 1.0/255)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "399e370a11a32f50f2e4ea451085b7fd4a15d358"
      },
      "cell_type": "code",
      "source": "def flow_from_dataframe(img_data_gen, in_df, path_col, y_col, **dflow_args):\n    base_dir = os.path.dirname(in_df[path_col].values[0])\n    print('## Ignore next message from keras, values are replaced anyways')\n    df_gen = img_data_gen.flow_from_directory(base_dir, \n                                     class_mode = 'sparse',\n                                    **dflow_args)\n    df_gen.filenames = in_df[path_col].values\n    df_gen.classes = np.stack(in_df[y_col].values)\n    df_gen.samples = in_df.shape[0]\n    df_gen.n = in_df.shape[0]\n    df_gen._set_index_array()\n    df_gen.directory = '' # since we have the full path\n    print('Reinserting dataframe: {} images'.format(in_df.shape[0]))\n    return df_gen",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f6b9b7c71ac5db56502fe84b244dd02f59d6a8e8"
      },
      "cell_type": "code",
      "source": "train_gen = flow_from_dataframe(core_idg, train_df, \n                             path_col = 'path',\n                            y_col = 'NumLabel', \n                            target_size = IMG_SIZE,\n                             color_mode = 'rgb',\n                            batch_size = 32)\n\nvalid_gen = flow_from_dataframe(val_idg, test_df, \n                             path_col = 'path',\n                            y_col = 'NumLabel', \n                            target_size = IMG_SIZE,\n                             color_mode = 'rgb',\n                            batch_size = 32) # we can use much larger batches for evaluation\n# used a fixed dataset for evaluating the algorithm\ntest_X, test_Y = next(flow_from_dataframe(val_idg, \n                               test_df, \n                             path_col = 'path',\n                            y_col = 'NumLabel', \n                            target_size = IMG_SIZE,\n                             color_mode = 'rgb',\n                            batch_size = 32)) # one big batch",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c4b03883e27957a4bf341bea70d4f17395729bb0"
      },
      "cell_type": "code",
      "source": "print(test_Y.shape)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3c593ea9139081dad8fd5d1028419c2d0334d3a9"
      },
      "cell_type": "markdown",
      "source": "t_x, t_y = next(train_gen)\nfig, m_axs = plt.subplots(4, 4, figsize = (16, 16))\nfor (c_x, c_y, c_ax) in zip(t_x, t_y, m_axs.flatten()):\n    c_ax.imshow(c_x[:,:,0], cmap = 'bone', vmin = -1.5, vmax = 1.5)\n    c_ax.set_title(', '.join([n_class for n_class, n_score in zip(all_labels, c_y) \n                             if n_score>0.5]))\n    c_ax.axis('off')"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a07564c9514904b6715bb3d4d91d1b6f2043d53e"
      },
      "cell_type": "markdown",
      "source": "def get_data():\n    imgs_x = []\n    label_y = []\n    for index, row in labels.iterrows():\n        if row['image'].shape == (1024,1024):\n            imgs_x.append(cv2.resize(row['image'], (150,150), interpolation=cv2.INTER_AREA))\n            label_y.append(row['NumLabel'])\n    return imgs_x, label_y    "
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "464984086d4b0b0a548ca3a5b6274031b83d0e37"
      },
      "cell_type": "markdown",
      "source": "X, Y = get_data()\nX = np.array(X)/255\nX= np.reshape(X, X.shape + (1,))\nY = np.array(Y)"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8e76e57c7c4c2adc59f9d9df4ea9769cbfbcb691"
      },
      "cell_type": "markdown",
      "source": "X.shape"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ffa5d9e8956866d5319a9c4ed49b05da1d99bfce"
      },
      "cell_type": "markdown",
      "source": "from sklearn.model_selection import train_test_split    \nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.18, random_state=2018)\nprint('Train Shape', X_train.shape, 'test shape', X_test.shape)"
    },
    {
      "metadata": {
        "_uuid": "73a4c6fedbae7bb449a3485bbee4f659b8da1b8e"
      },
      "cell_type": "markdown",
      "source": "# from keras.models import Sequential\nfrom keras.models import Sequential\n#from keras.applications.mobilenet import MobileNet\nfrom keras.utils.vis_utils import plot_model\nfrom keras.layers import Conv2D, MaxPooling2D, BatchNormalization\nfrom keras.layers import Dense, Dropout, Activation, Flatten, GlobalAveragePooling2D\nfrom keras.optimizers import Adam, SGD, RMSprop\nfrom keras import regularizers\nfrom keras.callbacks import EarlyStopping"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "794cd4e131a886d79d830dbc234ec120e37a7388"
      },
      "cell_type": "code",
      "source": "base_model = VGG16(input_shape =  (IMG_SIZE[0],IMG_SIZE[1],3), \n                                 include_top = False, weights = 'imagenet')\n#base_model.trainable = False\nfor layer in base_model.layers[:-4]:\n    layer.trainable= False\nfor layer in base_model.layers:\n    if 'bn' in layer.name:\n        layer.trainable = False\n    print(layer,layer.trainable)\nprint (len(base_model.layers))\nmulti_disease_model = Sequential()\nmulti_disease_model.add(base_model)\nmulti_disease_model.add(Dropout(0.25))\nmulti_disease_model.add(GlobalAveragePooling2D())\nmulti_disease_model.add(Dense(512, activation = 'relu'))\n#multi_disease_model.add(Dense(512,activation = 'relu',kernel_regularizer=regularizers.l2(0.0001)))\nmulti_disease_model.add(BatchNormalization())\n#multi_disease_model.add(Dropout(0.5))\nmulti_disease_model.add(Dense(1, activation = 'sigmoid'))\nmulti_disease_model.compile(optimizer = \"adam\", loss = 'binary_crossentropy',\n                           metrics = ['accuracy', 'mae'])\nmulti_disease_model.summary()\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b1f038c83de6ec8aed3fa2f936d3662622f1a7e2"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "60a51e08178f50158e9d4e11c1172328ad3ee1e2",
        "trusted": true
      },
      "cell_type": "code",
      "source": "from keras.layers import GlobalAveragePooling2D, Dense, Dropout, Flatten, Input, Conv2D, multiply, LocallyConnected2D, Lambda, AvgPool2D\nfrom keras.models import Model\nfrom keras.layers import BatchNormalization\n\nbase_model = VGG16(input_shape =  (IMG_SIZE[0],IMG_SIZE[1],3), \n                                 include_top = False, weights = 'imagenet')\nbase_model.trainable = False\n#for layer in base_model.layers[:-4]:\n#    layer.trainable= False\nfor layer in base_model.layers:\n    if 'bn' in layer.name:\n        layer.trainable = False\n    print(layer,layer.trainable)\n\npt_features = Input(base_model.get_output_shape_at(0)[1:], name = 'feature_input')\npt_depth = base_model.get_output_shape_at(0)[-1]\n#print(base_model.get_output_shape_at(0)[-1])\nbn_features = BatchNormalization()(pt_features)\n\n# here we do an attention mechanism to turn pixels in the GAP on an off\nattn_layer = Conv2D(128, kernel_size = (1,1), padding = 'same', activation = 'elu')(bn_features)\nattn_layer = Conv2D(32, kernel_size = (1,1), padding = 'same', activation = 'elu')(attn_layer)\nattn_layer = Conv2D(16, kernel_size = (1,1), padding = 'same', activation = 'elu')(attn_layer)\nattn_layer = AvgPool2D((2,2), strides = (1,1), padding = 'same')(attn_layer) # smooth results\nattn_layer = Conv2D(1, \n                    kernel_size = (1,1), \n                    padding = 'valid', \n                    activation = 'sigmoid')(attn_layer)\n# fan it out to all of the channels\nup_c2_w = np.ones((1, 1, 1, pt_depth))\nup_c2 = Conv2D(pt_depth, kernel_size = (1,1), padding = 'same', \n               activation = 'linear', use_bias = False, weights = [up_c2_w])\nup_c2.trainable = False\nattn_layer = up_c2(attn_layer)\n\nmask_features = multiply([attn_layer, bn_features])\ngap_features = GlobalAveragePooling2D()(mask_features)\ngap_mask = GlobalAveragePooling2D()(attn_layer)\n# to account for missing values from the attention model\ngap = Lambda(lambda x: x[0]/x[1], name = 'RescaleGAP')([gap_features, gap_mask])\ngap_dr = Dropout(0.5)(gap)\ndr_steps = Dropout(0.5)(Dense(128, activation = 'elu')(gap_dr))\nout_layer = Dense(1, activation = 'sigmoid')(dr_steps)\n\nattn_model = Model(inputs = [pt_features], outputs = [out_layer], name = 'attention_model')\n\nattn_model.compile(optimizer = 'adam', loss = 'binary_crossentropy',\n                           metrics = ['binary_accuracy'])\n\nattn_model.summary()    ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "c2d0dbb5452fd6a96a3f0e901c6a5c6bc252495d",
        "trusted": true
      },
      "cell_type": "code",
      "source": "from keras.models import Sequential\nfrom keras.optimizers import Adam\ntb_model = Sequential(name = 'combined_model')\nbase_model.trainable = False\ntb_model.add(base_model)\ntb_model.add(attn_model)\ntb_model.compile(optimizer = Adam(lr = 1e-3), loss = 'binary_crossentropy',\n                           metrics = ['binary_accuracy'])\ntb_model.summary()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a4570a8b3c795bf66767fa7b2000d32d3982ad0c"
      },
      "cell_type": "code",
      "source": "\nbase_mobilenet_model = MobileNet(input_shape =  t_x.shape[1:], \n                                 include_top = False, weights = None)\n\nmodel = Sequential()\n\n# conv1\nmodel.add(Conv2D(16, kernel_size=(3,3),activation='relu', padding='same',input_shape=(128,128,3),kernel_regularizer=regularizers.l2(0.0001)))\nmodel.add(Conv2D(16, kernel_size=(3,3),activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\n# conv2\n#model.add(base_mobilenet_model)\n#model.add(GlobalAveragePooling2D())\n#model.add(Dropout(0.5))\nmodel.add(Conv2D(32, kernel_size=(3,3),activation='relu', padding='same',kernel_regularizer=regularizers.l2(0.0001)))\nmodel.add(Conv2D(32, kernel_size=(3,3),activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\n#conv3\nmodel.add(Conv2D(64, kernel_size=(3,3),activation='relu', padding='same',kernel_regularizer=regularizers.l2(0.0001)))\nmodel.add(Conv2D(64, kernel_size=(3,3),activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\n#conv4\nmodel.add(Conv2D(96, kernel_size=(3,3),dilation_rate = (2,2), activation='relu', padding='same',kernel_regularizer=regularizers.l2(0.0001)))\nmodel.add(Conv2D(96, kernel_size=(3,3),activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\n#conv5\nmodel.add(Conv2D(128, kernel_size=(3,3),dilation_rate = (2,2), activation='relu', padding='same',kernel_regularizer=regularizers.l2(0.0001)))\nmodel.add(Conv2D(128, kernel_size=(3,3),activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\n# fc\nmodel.add(Flatten())\nmodel.add(BatchNormalization())\nmodel.add(Dense(512, activation='relu',kernel_regularizer=regularizers.l2(0.0001)))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1, activation='sigmoid'))\n\nmodel.compile(loss='binary_crossentropy', optimizer=\"adam\", metrics=['accuracy','mae'])\nmodel.summary()\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9dc86c06287f46e9d36e883ae3d018c02ea4d8e9"
      },
      "cell_type": "code",
      "source": "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n\nweight_path=\"{}_weights.best.hdf5\".format('xray_class')\ncheckpoint = ModelCheckpoint(weight_path, monitor='val_acc', verbose=1, \n                             save_best_only=True, mode='max', save_weights_only = True)\n\nearly = EarlyStopping(monitor=\"val_loss\", \n                      mode=\"min\", \n                      patience=5)\ncallbacks_list = [checkpoint, early]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "dd8f1054ba3aa6b4b63f2f5a862ea8a3049d2ca4",
        "scrolled": true
      },
      "cell_type": "code",
      "source": "multi_disease_model.fit_generator(train_gen, \n                    steps_per_epoch=train_gen.samples//train_gen.batch_size,\n                    validation_data = valid_gen,\n                    validation_steps = valid_gen.samples//valid_gen.batch_size,\n                    epochs = 4, \n                    callbacks = callbacks_list)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "1645e1057fd334c2d85514138541d501ba3fea71"
      },
      "cell_type": "markdown",
      "source": "history = model.fit(X_train, y_train, epochs = 10, batch_size = 32, verbose=1, validation_data=(X_test, y_test),callbacks=[EarlyStopping(monitor='val_binary_accuracy', patience=5)])"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8f98db298ab48c295b61ac2a7022dc82f44041ba",
        "scrolled": true
      },
      "cell_type": "code",
      "source": "history = multi_disease_model.fit_generator(train_gen, \n                            steps_per_epoch = train_gen.samples//train_gen.batch_size,\n                            validation_data =  valid_gen, \n                            validation_steps = valid_gen.samples//valid_gen.batch_size,\n                            epochs = 15, \n                            callbacks = callbacks_list)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3928e618240467b5da5ae8b983ac908af811badc",
        "scrolled": false
      },
      "cell_type": "code",
      "source": "import matplotlib.pyplot as plt\n\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n#fig.savefig('model_accuracy.png', dpi=300)\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n#fig.savefig('model_loss.png', dpi=300)",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}