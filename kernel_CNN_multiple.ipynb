{
  "cells": [
    {
      "metadata": {
        "_cell_guid": "19ff9d0b-d32d-4325-a19f-2ccbfa7d2dff",
        "_uuid": "9206c5863724e1af01281071e0f0ee5109ef431b"
      },
      "cell_type": "markdown",
      "source": "# Goal\nThe goal is to use a simple model to classify x-ray images in Keras, the notebook how to use the ```flow_from_dataframe``` to deal with messier datasets"
    },
    {
      "metadata": {
        "_cell_guid": "f42f6560-edf0-4efb-85a6-6e945e50895b",
        "_uuid": "3300a1edbf2e8122d88093998eb503a6fab8a719",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom skimage.io import imread\nimport cv2\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nfrom glob import glob\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "91515e0332ae8329d3aa728ee2fe5eeba329b3db"
      },
      "cell_type": "code",
      "source": "!ls ../input/sample/sample",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "cf249b3e8fac1f85d3b9757102b8eb8ce5d73b52"
      },
      "cell_type": "code",
      "source": "!mkdir ~/.keras\n!mkdir ~/.keras/models\n!cp ../input/keraspretrainedmodels/keras-pretrained-models/*notop* ~/.keras/models/\n!cp ../input/keraspretrainedmodels/keras-pretrained-models/imagenet_class_index.json ~/.keras/models/\n#!cp ../input/keraspretrainedmodels/keras-pretrained-models/resnet50* ~/.keras/models/",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f91d2545ff5ccbd5633db0983ed0622b9ceb5e2e"
      },
      "cell_type": "markdown",
      "source": "import os\n\ncache_dir = os.path.expanduser(os.path.join('~', '.keras'))\nif not os.path.exists(cache_dir):\n    os.makedirs(cache_dir)\n\n# Create symbolic links for trained models.\n# Thanks to Lem Lordje Ko for the idea\n# https://www.kaggle.com/lemonkoala/pretrained-keras-models-symlinked-not-copied\nmodels_symlink = os.path.join(cache_dir, 'models')\nif not os.path.exists(models_symlink):\n    os.symlink('/kaggle/input/keras-pretrained-models/', models_symlink)"
    },
    {
      "metadata": {
        "_cell_guid": "9a342cdc-0823-490d-9a3a-a53fb7c33727",
        "_uuid": "fe804e7c294e2d290e27b037bf1ba56177abab70",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# ../input/\nPATH = os.path.abspath(os.path.join('..', 'input'))\n\n# ../input/sample/images/\nSOURCE_IMAGES = os.path.join(PATH, \"sample\", \"sample\",\"images\")\n\n# ../input/sample/images/*.png\nimages = glob(os.path.join(SOURCE_IMAGES, \"*.png\"))\n\n# Load labels\nall_xray_df = pd.read_csv('../input/sample/sample_labels.csv')\nall_image_paths = {os.path.basename(x): x for x in images}\nprint('Scans found:', len(all_image_paths), ', Total Headers', all_xray_df.shape[0])\nall_xray_df['path'] = all_xray_df['Image Index'].map(all_image_paths.get)\nall_xray_df['Patient Age'] = all_xray_df['Patient Age'].map(lambda x: int(x[:-1]))\nall_xray_df.sample(3)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "0d674a43-170f-4ca6-a9b4-edc64ab89c35",
        "_uuid": "9a1669750b7cffcae1b7a2eb4307b85472dff192"
      },
      "cell_type": "markdown",
      "source": "# Preprocessing Labels\nHere we take the labels and make them into a more clear format. The primary step is to see the distribution of findings and then to convert them to simple binary labels"
    },
    {
      "metadata": {
        "_uuid": "b87d40c44b5c96883d717329804cf9a21ac67e2a"
      },
      "cell_type": "markdown",
      "source": "all_xray_df['Finding Labels'].value_counts()[:10]"
    },
    {
      "metadata": {
        "_cell_guid": "d75ed03e-986d-4f3f-81af-c910d194f390",
        "_uuid": "0c5123f65edf349f8ad2e5c5f55ac484d974f5c7",
        "trusted": true
      },
      "cell_type": "code",
      "source": "label_counts = all_xray_df['Finding Labels'].value_counts()[:15]\nfig, ax1 = plt.subplots(1,1,figsize = (12, 8))\nax1.bar(np.arange(len(label_counts))+0.5, label_counts)\nax1.set_xticks(np.arange(len(label_counts))+0.5)\n_ = ax1.set_xticklabels(label_counts.index, rotation = 90)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "d4127ee6d583612dca0f6600f6c488fe38b0ce4b"
      },
      "cell_type": "markdown",
      "source": "all_xray_df[all_xray_df['Finding Labels']!= 'No Finding'].shape"
    },
    {
      "metadata": {
        "_cell_guid": "a9ff3a04-254d-4667-b0a3-869bbd92b08b",
        "_uuid": "78b4425b0a8932bb33864b5a3712611004687a48",
        "trusted": true
      },
      "cell_type": "code",
      "source": "all_xray_df['Finding Labels'] = all_xray_df['Finding Labels'].map(lambda x: x.replace('No Finding', ''))\nfrom itertools import chain\nall_labels = np.unique(list(chain(*all_xray_df['Finding Labels'].map(lambda x: x.split('|')).tolist())))\nall_labels = [x for x in all_labels if len(x)>0]\nprint('All Labels ({}): {}'.format(len(all_labels), all_labels))\nfor c_label in all_labels:\n    if len(c_label)>1: # leave out empty labels\n        all_xray_df[c_label] = all_xray_df['Finding Labels'].map(lambda finding: 1.0 if c_label in finding else 0)\nall_xray_df.head(5)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "05b6c7d9-4869-40b5-a70b-53957c69f021",
        "_uuid": "64653f9f57d3a5b952f1f1a709eb70ca38761a0d"
      },
      "cell_type": "markdown",
      "source": "### Clean categories\nSince we have too many categories, we can prune a few out by taking the ones with only a few examples"
    },
    {
      "metadata": {
        "_cell_guid": "dd273e26-63ab-4d76-925d-9c1c2c1ba69c",
        "_uuid": "9f368f9ea8947d8fc1dacf3988c58b6a2bf5fffc",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# keep at least 1000 cases\nMIN_CASES = 200\nall_labels = [c_label for c_label in all_labels if all_xray_df[c_label].sum()>MIN_CASES]\nprint('Clean Labels ({})'.format(len(all_labels)), \n      [(c_label,int(all_xray_df[c_label].sum())) for c_label in all_labels])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a3e882e986c7481eb4aff4ec714742ffe2539a27"
      },
      "cell_type": "code",
      "source": "sample_weights = all_xray_df['Finding Labels'].map(lambda x: len(x.split('|')) if len(x)>0 else 0).values + 4e-2\nlen(sample_weights)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "b3f8a05870f61b1a4db9ad91e26149e18b573e8e"
      },
      "cell_type": "markdown",
      "source": "all_xray_df['Finding Labels'].map(lambda x: len(x.split('|')) if len(x)>0 else 0).value_counts()"
    },
    {
      "metadata": {
        "_cell_guid": "01478f44-5beb-4a6c-aa27-77db4b9abf10",
        "_uuid": "cf071cfa49f2886d9795cdf6067a8afdafd6f458",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# since the dataset is very unbiased, we can resample it to be a more reasonable collection\n# weight is 0.1 + number of findings\nsample_weights = all_xray_df['Finding Labels'].map(lambda x: len(x.split('|')) if len(x)>0 else 0).values + 4e-2\nsample_weights /= sample_weights.sum()\nall_xray_df = all_xray_df.sample(5000, weights=sample_weights)\n\nlabel_counts = all_xray_df['Finding Labels'].value_counts()[:15]\nfig, ax1 = plt.subplots(1,1,figsize = (12, 8))\nax1.bar(np.arange(len(label_counts))+0.5, label_counts)\nax1.set_xticks(np.arange(len(label_counts))+0.5)\n_ = ax1.set_xticklabels(label_counts.index, rotation = 90)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "277caf38-f13d-4939-9eef-55efaf73020e",
        "_uuid": "cb9f18a64740580e1c541b8631d45720be5f36fe",
        "trusted": true
      },
      "cell_type": "code",
      "source": "label_counts = 100*np.mean(all_xray_df[all_labels].values,0)\nfig, ax1 = plt.subplots(1,1,figsize = (12, 8))\nax1.bar(np.arange(len(label_counts))+0.5, label_counts)\nax1.set_xticks(np.arange(len(label_counts))+0.5)\nax1.set_xticklabels(all_labels, rotation = 90)\nax1.set_title('Adjusted Frequency of Diseases in Patient Group')\n_ = ax1.set_ylabel('Frequency (%)')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "a1367d63-4c7b-4e47-b19f-9a26d1f89476",
        "_uuid": "6ed6489bbd618fb419ceca2bbd8c300694f1d4ed",
        "scrolled": true
      },
      "cell_type": "markdown",
      "source": "# Prepare Training Data\nHere we split the data into training and validation sets and create a single vector (disease_vec) with the 0/1 outputs for the disease status (what the model will try and predict)"
    },
    {
      "metadata": {
        "_cell_guid": "185ae07c-17a2-46d3-81ca-4007e88cbf86",
        "_uuid": "6f82e5ae33e1c0fcfa33ac51a26885cb5a0e6bb1",
        "trusted": true
      },
      "cell_type": "code",
      "source": "all_xray_df['disease_vec'] = all_xray_df.apply(lambda x: [x[all_labels].values], 1).map(lambda x: x[0])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5fe314eca7e36c3cf2c2f0f4dd996fffff6f04a4"
      },
      "cell_type": "markdown",
      "source": "all_xray_df.head(5)"
    },
    {
      "metadata": {
        "_cell_guid": "5feddc96-7958-4d34-81f1-10eba94ab1b6",
        "_uuid": "8c7dc722de08243cc763d23928708f9c040bbdc6",
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.model_selection import train_test_split\ntrain_df, valid_df = train_test_split(all_xray_df, \n                                   test_size = 0.2, \n                                   random_state = 2018,\n                                   stratify = all_xray_df[['Patient Gender']])\nprint('train', train_df.shape[0], 'validation', valid_df.shape[0])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "7178cb8d-f220-4422-93ae-2469f0c97493",
        "_uuid": "0115346eb989e7eaeffa3643d05c654ec5ceb7c2"
      },
      "cell_type": "markdown",
      "source": "# Create Data Generators\nHere we make the data generators for loading and randomly transforming images"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a1b5687116c2f9063b1f6af88788b4ac9acf4514"
      },
      "cell_type": "code",
      "source": "#from keras.applications.mobilenet import MobileNet\n#from keras.applications.resnet50 import ResNet50, preprocess_input\nfrom keras.applications.vgg16 import VGG16, preprocess_input\n#from keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\nfrom keras.layers import GlobalAveragePooling2D, Dense, Dropout, Flatten\nfrom keras.models import Sequential\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.optimizers import Adam, RMSprop",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "30eaf01b-8ec0-4407-9d25-f87ca1f48e8a",
        "_uuid": "b5e42124376584390e925a06c4cee564285e43b3",
        "trusted": true
      },
      "cell_type": "code",
      "source": "\nIMG_SIZE = (128, 128)\ncore_idg = ImageDataGenerator(preprocessing_function=preprocess_input,\n                              samplewise_center=True, \n                              samplewise_std_normalization=True, \n                              horizontal_flip = True, \n                              vertical_flip = False, \n                              height_shift_range= 0.15, \n                              width_shift_range=0.15, \n                              rotation_range=40, \n                              shear_range = 0.15,\n                              fill_mode = 'nearest',\n                              zoom_range=0.15)\nval_idg = ImageDataGenerator(preprocessing_function=preprocess_input)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "b67dc5fa-d91b-420a-aaa7-b3991313127a",
        "_uuid": "dbb93f7f8248031563ec7042d978650c0c957c1f",
        "trusted": true
      },
      "cell_type": "code",
      "source": "def flow_from_dataframe(img_data_gen, in_df, path_col, y_col, **dflow_args):\n    base_dir = os.path.dirname(in_df[path_col].values[0])\n    print('## Ignore next message from keras, values are replaced anyways')\n    df_gen = img_data_gen.flow_from_directory(base_dir, \n                                     class_mode = 'sparse',\n                                    **dflow_args)\n    df_gen.filenames = in_df[path_col].values\n    df_gen.classes = np.stack(in_df[y_col].values)\n    df_gen.samples = in_df.shape[0]\n    df_gen.n = in_df.shape[0]\n    df_gen._set_index_array()\n    df_gen.directory = '' # since we have the full path\n    print('Reinserting dataframe: {} images'.format(in_df.shape[0]))\n    return df_gen",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "dc4d027c-f5c4-48b8-8ab6-b41971ad514f",
        "_uuid": "cc92b74f28987fee4971e60a71f74660693f4278",
        "trusted": true
      },
      "cell_type": "code",
      "source": "train_gen = flow_from_dataframe(val_idg, train_df, \n                             path_col = 'path',\n                            y_col = 'disease_vec', \n                            target_size = IMG_SIZE,\n                             color_mode = 'rgb',\n                            batch_size = 32)\n\nvalid_gen = flow_from_dataframe(val_idg, valid_df, \n                             path_col = 'path',\n                            y_col = 'disease_vec', \n                            target_size = IMG_SIZE,\n                             color_mode = 'rgb',\n                            batch_size = 32) # we can use much larger batches for evaluation\n# used a fixed dataset for evaluating the algorithm\ntest_X, test_Y = next(flow_from_dataframe(val_idg, \n                               valid_df, \n                             path_col = 'path',\n                            y_col = 'disease_vec', \n                            target_size = IMG_SIZE,\n                             color_mode = 'rgb',\n                            batch_size = 32)) # one big batch",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "0621048f-3d4c-4eb7-aaee-0c53f7cbf26a",
        "_uuid": "2852ef2fe07eb6d8e2caf056d1428d153afad65f",
        "trusted": true
      },
      "cell_type": "code",
      "source": "t_x, t_y = next(train_gen)\nfig, m_axs = plt.subplots(4, 4, figsize = (16, 16))\nfor (c_x, c_y, c_ax) in zip(t_x, t_y, m_axs.flatten()):\n    c_ax.imshow(c_x[:,:,0], cmap = 'bone', vmin = -1.5, vmax = 1.5)\n    c_ax.set_title(', '.join([n_class for n_class, n_score in zip(all_labels, c_y) \n                             if n_score>0.5]))\n    c_ax.axis('off')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "cce3c89c-4292-4092-9317-ca066d72e354",
        "_uuid": "5b0ec78f2ffa8137dce37744f38a40782aafb54d"
      },
      "cell_type": "markdown",
      "source": "# Create a simple model\nHere we make a simple model to train using MobileNet as a base and then adding a GAP layer (Flatten could also be added), dropout, and a fully-connected layer to calculate specific features"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "428d0dee049a3f1614e2046bbde684f11a58642d"
      },
      "cell_type": "code",
      "source": "# from keras.models import Sequential\nfrom keras.models import Sequential\nfrom keras.utils.vis_utils import plot_model\nfrom keras.layers import Conv2D, MaxPooling2D, BatchNormalization\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.optimizers import SGD, RMSprop, Adam\n\n\nmodel = Sequential()\n# conv1\nmodel.add(Conv2D(16, kernel_size=(3,3),activation='relu', padding='same',input_shape=(IMG_SIZE[0],IMG_SIZE[1],3)))\nmodel.add(Conv2D(16, kernel_size=(3,3),activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\n# conv2\nmodel.add(Conv2D(32, kernel_size=(3,3),activation='relu', padding='same'))\nmodel.add(Conv2D(32, kernel_size=(3,3),activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\n#conv3\nmodel.add(Conv2D(64, kernel_size=(3,3),activation='relu', padding='same'))\nmodel.add(Conv2D(64, kernel_size=(3,3),activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\n#conv4\nmodel.add(Conv2D(96, kernel_size=(3,3),dilation_rate = (2,2), activation='relu', padding='same'))\nmodel.add(Conv2D(96, kernel_size=(3,3),activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\n#conv5\nmodel.add(Conv2D(128, kernel_size=(3,3),dilation_rate = (2,2), activation='relu', padding='same'))\nmodel.add(Conv2D(128, kernel_size=(3,3),activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\n# fc\nmodel.add(Flatten())\nmodel.add(BatchNormalization())\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(len(all_labels), activation='sigmoid'))\n\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel.summary()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "235846d4-3ef1-4888-a276-6134ad572415",
        "_uuid": "a447f8cc7274c06555849a40881fb903aca7001a",
        "trusted": true
      },
      "cell_type": "markdown",
      "source": "\nbase_model = VGG16(input_shape =  (IMG_SIZE[0],IMG_SIZE[1],3), \n                                 include_top = False, weights = 'imagenet')\nbase_model.trainable = False\nmulti_disease_model = Sequential()\nmulti_disease_model.add(base_model)\nmulti_disease_model.add(GlobalAveragePooling2D())\nmulti_disease_model.add(Dropout(0.5))\nmulti_disease_model.add(Dense(512))\nmulti_disease_model.add(Dropout(0.5))\nmulti_disease_model.add(Dense(len(all_labels), activation = 'sigmoid'))\nmulti_disease_model.compile(optimizer = \"adam\", loss = 'binary_crossentropy',\n                           metrics = ['binary_accuracy', 'mae'])\nmulti_disease_model.summary()"
    },
    {
      "metadata": {
        "_cell_guid": "1acd1753-dae2-440d-a9d5-f3bbebfe446f",
        "_uuid": "90a131f99bea8b77fba54024e261a97e24dfc6c1",
        "trusted": true
      },
      "cell_type": "code",
      "source": "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n\nweight_path=\"{}_weights.best.hdf5\".format('xray_class')\ncheckpoint = ModelCheckpoint(weight_path, monitor='val_acc', verbose=1, \n                             save_best_only=True, mode='max', save_weights_only = True)\n\nearly = EarlyStopping(monitor=\"val_loss\", \n                      mode=\"min\", \n                      patience=5)\ncallbacks_list = [checkpoint, early]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "e5ad629e-15a3-4c96-ac74-db8077b101fe",
        "_uuid": "eba5247e4a767def4b4ead6e2f02f3c334edbbf0"
      },
      "cell_type": "markdown",
      "source": "# First Round\nHere we do a first round of training to get a few initial low hanging fruit results"
    },
    {
      "metadata": {
        "_cell_guid": "c269083c-7617-4c16-8f96-353c1f3d8eef",
        "_uuid": "cbdfcf827510dfb3bdba6ab08ff60e21838d6987",
        "trusted": true
      },
      "cell_type": "code",
      "source": "model.fit_generator(train_gen, \n                                  steps_per_epoch=train_gen.samples//train_gen.batch_size,\n                                  validation_data = valid_gen,\n                                  validation_steps = valid_gen.samples//valid_gen.batch_size,\n                                  epochs = 1, \n                                  callbacks = callbacks_list)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "571df602-c0f1-4ba0-9f1e-0c9fdc10eff3",
        "_uuid": "392f3973459dcbb3fc998191baca4d047995d351"
      },
      "cell_type": "markdown",
      "source": "# Check Output\nHere we see how many positive examples we have of each category"
    },
    {
      "metadata": {
        "_cell_guid": "d9f519ef-4b4f-4bd9-8989-643b21cb8904",
        "_uuid": "308a85cd454ad05e451ec1db99432c6fe85e8e41",
        "trusted": true
      },
      "cell_type": "markdown",
      "source": "for c_label, s_count in zip(all_labels, 100*np.mean(test_Y,0)):\n    print('%s: %2.2f%%' % (c_label, s_count))"
    },
    {
      "metadata": {
        "_cell_guid": "73a8dba1-3d8e-47ec-b945-3101ad57dcef",
        "_uuid": "0878962d872569c57b0f959751c522ae928f92e3",
        "trusted": true
      },
      "cell_type": "markdown",
      "source": "pred_Y = multi_disease_model.predict(test_X, batch_size = 32, verbose = True)"
    },
    {
      "metadata": {
        "_cell_guid": "7a0fc649-158c-4844-9b05-f6a62214009f",
        "_uuid": "4acd4919e0ba24e2d06ef75fbb054a907a582c7a"
      },
      "cell_type": "markdown",
      "source": "# ROC Curves\nWhile a very oversimplified metric, we can show the ROC curve for each metric"
    },
    {
      "metadata": {
        "_cell_guid": "cc076f02-0bf2-4d3f-a6ab-f192bed9e6a9",
        "_uuid": "d7168d90928d842c295c64e2446e84eb068fd391",
        "trusted": false
      },
      "cell_type": "markdown",
      "source": "from sklearn.metrics import roc_curve, auc\nfig, c_ax = plt.subplots(1,1, figsize = (9, 9))\nfor (idx, c_label) in enumerate(all_labels):\n    fpr, tpr, thresholds = roc_curve(test_Y[:,idx].astype(int), pred_Y[:,idx])\n    c_ax.plot(fpr, tpr, label = '%s (AUC:%0.2f)'  % (c_label, auc(fpr, tpr)))\nc_ax.legend()\nc_ax.set_xlabel('False Positive Rate')\nc_ax.set_ylabel('True Positive Rate')\nfig.savefig('barely_trained_net.png')"
    },
    {
      "metadata": {
        "_cell_guid": "6c2fe734-8f87-4537-81e0-d0ce68bc2545",
        "_uuid": "8a03574bc1f2b3441538c2408fc158324d6d23df",
        "collapsed": true
      },
      "cell_type": "markdown",
      "source": "# Continued Training\nNow we do a much longer training process to see how the results improve"
    },
    {
      "metadata": {
        "_cell_guid": "80b6ede7-052b-4fa2-ab97-bed0199db681",
        "_uuid": "0b35cd7ef77680d2aa180812622d89388b8fff63",
        "trusted": true
      },
      "cell_type": "code",
      "source": "history = model.fit_generator(train_gen, \n                                  steps_per_epoch = train_gen.samples//train_gen.batch_size,\n                                  validation_data =  valid_gen, \n                                  validation_steps = valid_gen.samples//valid_gen.batch_size,\n                                  epochs = 15, \n                                  callbacks = callbacks_list)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "74c46b271dfbe553973d56749abdae0b6484a2fb"
      },
      "cell_type": "code",
      "source": "import matplotlib.pyplot as plt\n\nplt.plot(history.history['binary_accuracy'])\nplt.plot(history.history['val_binary_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.ylim(0.8,0.96)\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\nfig.savefig('model_accuracy.png', dpi=300)\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\nfig.savefig('model_loss.png', dpi=300)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "9447be5c648631b08da06acba1c89583466dc166",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# load the best weights\nmulti_disease_model.load_weights(weight_path)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "97dd6d26-8d12-4aa5-8544-6bde2f8200a6",
        "_uuid": "2f358c745432e497adfac31c6d97abc8b61bd0eb",
        "trusted": true
      },
      "cell_type": "code",
      "source": "pred_Y = multi_disease_model.predict(test_X, batch_size = 32, verbose = True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "3e754b40-8492-4f5b-a19f-a0bfd2c9b4f4",
        "_uuid": "db77f749926ac5936e860617b22713715a69157a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# look at how often the algorithm predicts certain diagnoses \nfor c_label, p_count, t_count in zip(all_labels, \n                                     100*np.mean(pred_Y,0), \n                                     100*np.mean(test_Y,0)):\n    print('%s: Dx: %2.2f%%, PDx: %2.2f%%' % (c_label, t_count, p_count))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "31990e46-1437-4945-aaa5-b31b377d6538",
        "_uuid": "a5dd26025391067cd0220b7502b193e5e095edbd",
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.metrics import roc_curve, auc\nfig, c_ax = plt.subplots(1,1, figsize = (9, 9))\nfor (idx, c_label) in enumerate(all_labels):\n    fpr, tpr, thresholds = roc_curve(test_Y[:,idx].astype(int), pred_Y[:,idx])\n    c_ax.plot(fpr, tpr, label = '%s (AUC:%0.2f)'  % (c_label, auc(fpr, tpr)))\nc_ax.legend()\nc_ax.set_xlabel('False Positive Rate')\nc_ax.set_ylabel('True Positive Rate')\nfig.savefig('trained_net.png')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "a50931b1-4d88-4b2f-93f7-ad3c9de31e5c",
        "_uuid": "8ad061d6b08b9ff383f682c35c8b55f30fb560a1"
      },
      "cell_type": "markdown",
      "source": "# Show a few images and associated predictions"
    },
    {
      "metadata": {
        "_cell_guid": "714ada59-850d-4d88-b983-2f9107f36e70",
        "_uuid": "e5191706a55a5ab8b68773d0b881aac4b020795a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "sickest_idx = np.argsort(np.sum(test_Y, 1)<1)\nfig, m_axs = plt.subplots(4, 2, figsize = (16, 32))\nfor (idx, c_ax) in zip(sickest_idx, m_axs.flatten()):\n    c_ax.imshow(test_X[idx, :,:,0], cmap = 'bone')\n    stat_str = [n_class[:6] for n_class, n_score in zip(all_labels, \n                                                                  test_Y[idx]) \n                             if n_score>0.5]\n    pred_str = ['%s:%2.0f%%' % (n_class[:4], p_score*100)  for n_class, n_score, p_score in zip(all_labels, \n                                                                  test_Y[idx], pred_Y[idx]) \n                             if (n_score>0.5) or (p_score>0.5)]\n    c_ax.set_title('Dx: '+', '.join(stat_str)+'\\nPDx: '+', '.join(pred_str))\n    c_ax.axis('off')\nfig.savefig('trained_img_predictions.png')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "48aff5bd-c927-44ae-abd3-1de884969d3b",
        "_uuid": "817ed988ed86bc7941065eeac676d1b50cef5d0b",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "68354276-ebbb-46ca-acd6-9e8cd1354bba",
        "_uuid": "6c186e1070db679fb62a4a08e4f42a7ece925aff",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}